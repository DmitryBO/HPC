# Лабораторная работа 1
## Перемножение матриц
**Задача**: реализовать алгоритм перемножения матриц<br/>
**Язык**: Python 3.9.7 с использованием библиотек Numpy, Numba<br/>
**Входные данные**: 2 матрицы размером от 100х100 до 2000х2000 каждая<br/>
**Выходные данные**: проверка корректности перемножения + время вычисления<br/>
### Для реализации данной задачи использовалась следующее техническое обеспечение:<br>
**CPU**: AMD Ryzen 5 2600 @ 3,4 GHz<br/>
**GPU**: NVIDIA GeForce GTX 1050 Ti<br/>
**RAM**: AMD Radeon R9 DDR4 2x8 GB<br/>
### Описание<br>

### Таблица результатов работы<br>
 Размерность матрицы | Результат |  Время на CPU, мсек | Время на GPU, мсек
:----:|:----:|:----:|:----:
| (240, 240)       | True        |           0.00725102 |            0.050676  |
| (400, 400)       | True        |           0.03475    |            0.0187505 |
| (560, 560)       | True        |           0.105125   |            0.0436243 |
| (720, 720)       | True        |           0.22875    |            0.0918745 |
| (880, 880)       | True        |           0.419876   |            0.166874  |
| (1040, 1040)     | True        |           0.6955     |            0.261876  |
| (1200, 1200)     | True        |           1.14013    |            0.341634  |
| (1360, 1360)     | True        |           1.92087    |            0.218884  |
| (1520, 1520)     | True        |           3.11725    |            0.33225   |
| (1680, 1680)     | True        |           4.39425    |            0.421126  |

### Графики результаты работы <br/>

![Графики_результатов](https://github.com/DmitryBO/HPC/blob/main/images/matmul.png)

### Вывод <br/>
Исходя из таблицы и графиков сделали вывод, что время работы функции на GPU превышает время работы на CPU, но только в случае с матрицами маленьких размерностей. С увеличением размерности матриц, скорость работы на GPU увеличивается в разы, что говорит о том, что использование функции на GPU следует только при расчёте матриц крупных размеров.
